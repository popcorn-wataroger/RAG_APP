# æ”¹å–„å®Ÿè£…ã®å¤‰æ›´ç‚¹ã¾ã¨ã‚

## âœ… å®Ÿè£…ã—ãŸæ”¹å–„

### 1. Document ã‚¯ãƒ©ã‚¹ã®å°å…¥ï¼ˆLangChain äº’æ›ï¼‰

**å¤‰æ›´å‰ï¼ˆdictï¼‰:**
```python
{
  "text": "<retrieved chunk text>",
  "metadata": {"source": "...", "chunk": 3}
}
```

**å¤‰æ›´å¾Œï¼ˆDocument ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼‰:**
```python
@dataclass
class Document:
    page_content: str
    metadata: Dict[str, any]
```

**ãƒ¡ãƒªãƒƒãƒˆ:**
- å‹å®‰å…¨æ€§ã®å‘ä¸Š
- IDE ã®è£œå®ŒãŒåŠ¹ã
- LangChain ã¨ã®äº’æ›æ€§
- ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ãŒè‡ªç„¶ã«æ›¸ã‘ã‚‹

---

### 2. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–

**è¿½åŠ ã•ã‚ŒãŸæ©Ÿèƒ½:**
```python
try:
    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if not os.path.exists(path):
        logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {path}")
        failed_files.append(path)
        continue
    
    # èª­ã¿è¾¼ã¿å‡¦ç†
    ...
    
except Exception as e:
    logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {path}: {e}")
    failed_files.append(path)
```

**æˆ»ã‚Šå€¤ã®æ”¹å–„:**
```python
return {
    "added_chunks": 43,
    "failed_files": [],      # NEW!
    "total_files": 2         # NEW!
}
```

---

### 3. ãƒ­ã‚®ãƒ³ã‚°æ©Ÿèƒ½ã®è¿½åŠ 

**å®Ÿè£…å†…å®¹:**
```python
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å„æ‰€ã§ãƒ­ã‚°å‡ºåŠ›
logger.info(f"âœ“ {path}: {len(chunks)} chunks")
logger.warning(f"ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«: {path}")
logger.error(f"ChromaDB è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
logger.info(f"æ¤œç´¢çµæœ: {len(results)} ä»¶")
```

**å‡ºåŠ›ä¾‹:**
```
INFO:rag:âœ“ data\sample.md: 43 chunks
WARNING:rag:ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«: data\sample.txt
INFO:rag:ChromaDB ã« 43 ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ 
INFO:rag:æ¤œç´¢çµæœ: 4 ä»¶
```

---

### 4. å‹ãƒ’ãƒ³ãƒˆã®å¼·åŒ–

**Before:**
```python
def retrieve(query: str, top_k: int = TOP_K) -> List[Dict]:
```

**After:**
```python
from typing import List, Dict, Optional
from dataclasses import dataclass

def retrieve(query: str, top_k: int = TOP_K) -> List[Document]:
    """
    ã‚¯ã‚¨ãƒªã«åŸºã¥ã„ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢
    
    Args:
        query: æ¤œç´¢ã‚¯ã‚¨ãƒª
        top_k: è¿”ã™çµæœã®æœ€å¤§æ•°
    
    Returns:
        Document ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ
    """
```

---

### 5. ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã®æ”¹å–„

**Before:**
```python
print("æ¤œç´¢çµæœä»¶æ•°:", len(results))
for r in results:
    print("-", r.page_content[:50])
```

**After:**
```python
print("\n" + "="*60)
print(f"æ¤œç´¢çµæœä»¶æ•°: {len(results)}")
print("="*60)

for i, doc in enumerate(results, 1):
    print(f"\n[çµæœ {i}]")
    print(f"ã‚½ãƒ¼ã‚¹: {doc.metadata.get('source', 'unknown')}")
    print(f"ãƒãƒ£ãƒ³ã‚¯: {doc.metadata.get('chunk', '?')}")
    print(f"å†…å®¹: {doc.page_content[:100]}...\n")
```

---

### 6. è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–

**settings.py ã«ã‚³ãƒ¡ãƒ³ãƒˆè¿½åŠ :**
```python
# ã€æ¨å¥¨å€¤ã€‘
# - æ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: 1000-1500 / 150-300
# - ã‚³ãƒ¼ãƒ‰ãƒ»æŠ€è¡“æ–‡æ›¸: 800-1200 / 100-200
# - PDFï¼ˆå¤§è¦æ¨¡ï¼‰: 1500-2000 / 200-400
CHUNK_SIZE = 1500
CHUNK_OVERLAP = 200
TOP_K = 4  # æ¤œç´¢çµæœã®æœ€å¤§ä»¶æ•°
```

---

## ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœ

```
INGEST TARGET FILES: ['data\\sample.md', 'data\\sample.txt']
INFO:rag:âœ“ data\sample.md: 43 chunks
WARNING:rag:ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«: data\sample.txt
INFO:rag:ChromaDB ã« 43 ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ 

Ingestçµæœ: {'added_chunks': 43, 'failed_files': [], 'total_files': 2}

æ¤œç´¢çµæœä»¶æ•°: 4
âœ“ Document ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ­£ã—ãå–å¾—
âœ“ metadata ã« source ã¨ chunk ãŒå«ã¾ã‚Œã‚‹
```

---

## ğŸ¯ è³ªå•ã¸ã®æœ€çµ‚å›ç­”

### Q1. retrieve ã®æˆ»ã‚Šå€¤è¨­è¨ˆ
**A: Document ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¤‰æ›´ã—ã¾ã—ãŸ**
- å‹å®‰å…¨æ€§å‘ä¸Š
- LangChain äº’æ›æ€§ç¢ºä¿
- ã‚³ãƒ¼ãƒ‰ã®å¯èª­æ€§å‘ä¸Š

### Q2. ingest API ã®æ‰±ã„
**A: èªè¨¼ä»˜ãã§æ®‹ã™ã“ã¨ã‚’æ¨å¥¨**
- `DESIGN_GUIDE.md` ã«å®Ÿè£…ä¾‹ã‚’è¨˜è¼‰
- é‹ç”¨ã§ã®æŸ”è»Ÿæ€§ã‚’ç¢ºä¿
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ãŒå¿…é ˆ

### Q3. chunk_size / chunk_overlap
**A: ç”¨é€”åˆ¥æ¨å¥¨å€¤ã‚’ DESIGN_GUIDE.md ã«æ•´ç†**
- æ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: 1000-1500 / 150-300
- ã‚³ãƒ¼ãƒ‰: 800-1200 / 100-200  
- PDF: 1500-2000 / 200-400

---

## ğŸ“ æ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«

1. **DESIGN_GUIDE.md** - è¨­è¨ˆæ–¹é‡ãƒ»ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã®å®Œå…¨ã‚¬ã‚¤ãƒ‰
2. **CHANGELOG.md**ï¼ˆã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰- æ”¹å–„å†…å®¹ã®ã¾ã¨ã‚

---

## ğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### æ¨å¥¨ã•ã‚Œã‚‹è¿½åŠ å®Ÿè£…

1. **API èªè¨¼ã®è¿½åŠ **
```python
from fastapi.security import HTTPBearer
# DESIGN_GUIDE.md å‚ç…§
```

2. **ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½**
```python
from functools import lru_cache
@lru_cache(maxsize=100)
def retrieve_cached(query: str):
    return retrieve(query)
```

3. **ãƒãƒƒãƒå‡¦ç†ã®æœ€é©åŒ–**
```python
BATCH_SIZE = 100
for batch in chunks(files, BATCH_SIZE):
    ingest_files(batch)
```

4. **ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã®è¿½åŠ **
```python
# pytest ã‚’ä½¿ã£ãŸè‡ªå‹•ãƒ†ã‚¹ãƒˆ
def test_document_structure():
    docs = retrieve("test")
    assert all(hasattr(d, 'page_content') for d in docs)
```

---

## ğŸ’¡ å‚è€ƒè³‡æ–™

- [DESIGN_GUIDE.md](DESIGN_GUIDE.md) - è¨­è¨ˆã‚¬ã‚¤ãƒ‰ï¼ˆæ–°è¦ä½œæˆï¼‰
- [README.md](README.md) - ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †
- [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

---

**æ”¹å–„å®Œäº†ï¼å®‰å…¨ã«å¤‰æ›´ã§ãã‚‹ RAG ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æ§‹æˆã«ãªã‚Šã¾ã—ãŸ âœ…**
