# RAG ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­è¨ˆã‚¬ã‚¤ãƒ‰

## ğŸ“– æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€RAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®è¨­è¨ˆæ–¹é‡ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚

---

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

### 1. ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

```
ãƒ•ã‚¡ã‚¤ãƒ« (.md/.txt/.pdf)
    â†“
ingest_files()  â† ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    â†“
ChromaDB (Persistent)
    â†“
retrieve()  â† ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
    â†“
Document ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    â†“
build_context_snippets()
    â†“
LLM (GPT-4o-mini)
```

---

## ğŸ¯ Q&Aï¼šè¨­è¨ˆåˆ¤æ–­

### Q1. retrieve ã®æˆ»ã‚Šå€¤è¨­è¨ˆã«ã¤ã„ã¦

**A: Document ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¨å¥¨**

#### âœ… æ¡ç”¨ã—ãŸè¨­è¨ˆ
```python
@dataclass
class Document:
    page_content: str
    metadata: Dict[str, any]
```

#### ç†ç”±
1. **LangChain äº’æ›æ€§**: å°†æ¥çš„ãªæ‹¡å¼µãŒå®¹æ˜“
2. **å‹å®‰å…¨æ€§**: IDE ã®è£œå®Œãƒ»å‹ãƒã‚§ãƒƒã‚¯ãŒåŠ¹ã
3. **å¯èª­æ€§**: `doc.page_content` ã®æ–¹ãŒç›´æ„Ÿçš„
4. **æ¨™æº–ãƒ‘ã‚¿ãƒ¼ãƒ³**: RAG å®Ÿè£…ã®äº‹å®Ÿä¸Šã®æ¨™æº–

#### âŒ dict ã‚’é¿ã‘ã‚‹ç†ç”±
```python
# éæ¨å¥¨
{"text": "...", "metadata": {...}}

# å•é¡Œç‚¹
- ã‚¿ã‚¤ãƒã«æ°—ã¥ãã«ãã„ï¼ˆr["txt"] ãªã©ï¼‰
- å‹æ¨è«–ãŒåŠ¹ã‹ãªã„
- IDE ã®ã‚µãƒãƒ¼ãƒˆãŒå¼±ã„
```

---

### Q2. ingest API ã‚’æ®‹ã™ã¹ãã‹ï¼Ÿ

**A: èªè¨¼ä»˜ãã§æ®‹ã™ï¼ˆé‹ç”¨å°‚ç”¨ API ã¨ã—ã¦ï¼‰**

#### å®Ÿè£…æ–¹é‡

```python
from fastapi import Depends, HTTPException
from fastapi.security import HTTPBearer

security = HTTPBearer()

@app.post("/ingest")
async def api_ingest(
    files: List[UploadFile],
    token: str = Depends(security)
):
    # èªè¨¼ãƒã‚§ãƒƒã‚¯
    if token.credentials != os.getenv("ADMIN_TOKEN"):
        raise HTTPException(401, "Unauthorized")
    
    # ingest å®Ÿè¡Œ
    ...
```

#### ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹
- âœ… ç®¡ç†è€…ã«ã‚ˆã‚‹æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
- âœ… ãƒãƒƒãƒå‡¦ç†ã§ã®å®šæœŸæ›´æ–°
- âœ… CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®ç™»éŒ²
- âŒ ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ç›´æ¥å‘¼ã³å‡ºã—ï¼ˆç¦æ­¢ï¼‰

---

### Q3. chunk_size / chunk_overlap ã®è€ƒãˆæ–¹

#### ç”¨é€”åˆ¥æ¨å¥¨å€¤

| ç”¨é€” | CHUNK_SIZE | CHUNK_OVERLAP | ç†ç”± |
|------|------------|---------------|------|
| **æ—¥æœ¬èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ** | 1000-1500 | 150-300 | å…¨è§’1æ–‡å­—=2-3byteã€‚æ–‡è„ˆã‚’ä¿æŒã™ã‚‹ãŸã‚ overlap ã¯ 15-20% |
| **ã‚³ãƒ¼ãƒ‰ãƒ»æŠ€è¡“æ–‡æ›¸** | 800-1200 | 100-200 | é–¢æ•°ãƒ»ã‚¯ãƒ©ã‚¹å˜ä½ã§åŒºåˆ‡ã‚Œã‚‹ã‚µã‚¤ã‚º |
| **PDFï¼ˆæ•°åãƒšãƒ¼ã‚¸ï¼‰** | 1500-2000 | 200-400 | ãƒšãƒ¼ã‚¸ã¾ãŸãå¯¾ç­–ã€‚overlap ã‚’å¤§ãã‚ã« |
| **FAQãƒ»çŸ­æ–‡** | 500-800 | 50-100 | 1è³ªå•1ãƒãƒ£ãƒ³ã‚¯ã‚’ç›®æŒ‡ã™ |

#### èª¿æ•´ã®æŒ‡é‡

```python
# æ—¥æœ¬èªä¸­å¿ƒã®å ´åˆ
CHUNK_SIZE = 1500  # å…¨è§’750æ–‡å­—ç¨‹åº¦
CHUNK_OVERLAP = 200  # ç´„13%

# è‹±èªä¸­å¿ƒã®å ´åˆ
CHUNK_SIZE = 1000  # ç´„250å˜èª
CHUNK_OVERLAP = 150  # 15%
```

#### âš ï¸ æ³¨æ„ç‚¹

1. **overlap ãŒå¤§ãã™ãã‚‹**
   - æ¤œç´¢çµæœãŒé‡è¤‡ã—ã‚„ã™ã„
   - ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å¢—åŠ 
   - æ¨å¥¨: chunk_size ã® 10-20%

2. **size ãŒå¤§ãã™ãã‚‹**
   - LLM ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆåˆ¶é™ã«å¼•ã£ã‹ã‹ã‚‹
   - é–¢é€£æ€§ã®ä½ã„æƒ…å ±ãŒæ··å…¥
   - æ¨å¥¨: 2000 ä»¥ä¸‹

3. **size ãŒå°ã•ã™ãã‚‹**
   - æ–‡è„ˆãŒå¤±ã‚ã‚Œã‚‹
   - æ¤œç´¢ç²¾åº¦ä½ä¸‹
   - æ¨å¥¨: 500 ä»¥ä¸Š

---

## ğŸ›¡ï¸ å®Ÿé‹ç”¨ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

```python
# å®Ÿè£…æ¸ˆã¿
try:
    raw = read_pdf(path)
except Exception as e:
    logger.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {path}: {e}")
    failed_files.append(path)
```

### 2. ãƒ­ã‚®ãƒ³ã‚°

```python
# å®Ÿè£…æ¸ˆã¿
logger.info(f"âœ“ {path}: {len(chunks)} chunks")
logger.warning(f"ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«: {path}")
logger.error(f"ChromaDB è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
```

### 3. æˆ»ã‚Šå€¤ã®è©³ç´°åŒ–

```python
# å®Ÿè£…æ¸ˆã¿
return {
    "added_chunks": 43,
    "failed_files": ["data/broken.pdf"],
    "total_files": 5
}
```

### 4. å‹ãƒ’ãƒ³ãƒˆã®å¾¹åº•

```python
# å®Ÿè£…æ¸ˆã¿
def retrieve(query: str, top_k: int = TOP_K) -> List[Document]:
```

---

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. ãƒãƒƒãƒå‡¦ç†

```python
# æ¨å¥¨: å¤§é‡ãƒ•ã‚¡ã‚¤ãƒ«ã¯åˆ†å‰²ã—ã¦ ingest
BATCH_SIZE = 100
for i in range(0, len(files), BATCH_SIZE):
    batch = files[i:i + BATCH_SIZE]
    ingest_files(batch)
```

### 2. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æœ€é©åŒ–

```python
# ChromaDB ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆæ™‚
collection = client.get_or_create_collection(
    name="docs",
    embedding_function=openai_ef,
    metadata={"hnsw:space": "cosine"}  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ l2
)
```

### 3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥

```python
# åŒã˜ã‚¯ã‚¨ãƒªã®çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
from functools import lru_cache

@lru_cache(maxsize=100)
def retrieve_cached(query: str) -> List[Document]:
    return retrieve(query)
```

---

## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

### 1. API èªè¨¼

```python
# ç’°å¢ƒå¤‰æ•°ã§ç®¡ç†
ADMIN_TOKEN = os.getenv("ADMIN_TOKEN")

# JWT æ¨å¥¨
from jose import jwt
```

### 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰åˆ¶é™

```python
# FastAPI è¨­å®š
app.add_middleware(
    TrustedHostMiddleware,
    allowed_hosts=["yourdomain.com"]
)

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
```

### 3. å…¥åŠ›æ¤œè¨¼

```python
# ãƒ‘ã‚¹ãƒˆãƒ©ãƒãƒ¼ã‚µãƒ«å¯¾ç­–
import os.path

def safe_file_path(path: str) -> str:
    if ".." in path or path.startswith("/"):
        raise ValueError("Invalid path")
    return os.path.normpath(path)
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆæˆ¦ç•¥

### 1. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

```python
# test_rag.py
def test_ingest_empty_file():
    result = ingest_files(["data/empty.txt"])
    assert result["added_chunks"] == 0

def test_retrieve_returns_documents():
    docs = retrieve("test query")
    assert all(isinstance(d, Document) for d in docs)
```

### 2. çµ±åˆãƒ†ã‚¹ãƒˆ

```bash
# å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã§å‹•ä½œç¢ºèª
python test_rag.py
```

---

## ğŸ“ˆ ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

### 1. ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

```python
# ãƒ­ã‚°ãƒ™ãƒ¼ã‚¹ã§ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
logger.info(f"æ¤œç´¢ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: {elapsed:.2f}s")
logger.info(f"å–å¾—ä»¶æ•°: {len(results)}")
```

### 2. ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

- ingest å¤±æ•—ç‡ãŒ 10% è¶…é
- æ¤œç´¢ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãŒ 3ç§’è¶…é
- ChromaDB ã‚µã‚¤ã‚ºãŒ 10GB è¶…é

---

## ğŸ”„ ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†

### 1. ã‚¹ã‚­ãƒ¼ãƒãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°

```python
# metadata ã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’è¿½åŠ 
metadatas.append({
    "source": path,
    "chunk": i,
    "schema_version": "1.0",  # è¿½åŠ 
    "ingest_date": datetime.now().isoformat()
})
```

### 2. ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

```python
# å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
def migrate_v0_to_v1():
    col = get_collection()
    # ãƒãƒƒãƒã§æ›´æ–°
    ...
```

---

## ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯

- [LangChain Document](https://python.langchain.com/docs/modules/data_connection/document_loaders/)
- [ChromaDB Best Practices](https://docs.trychroma.com/usage-guide)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)

---

## ğŸ“ ã¾ã¨ã‚

| é …ç›® | æ¨å¥¨ | ç†ç”± |
|------|------|------|
| æˆ»ã‚Šå€¤ | `Document` ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ | å‹å®‰å…¨æ€§ãƒ»æ‹¡å¼µæ€§ |
| ingest API | èªè¨¼ä»˜ãã§æ®‹ã™ | é‹ç”¨ã§ã®æŸ”è»Ÿæ€§ |
| chunk_size | 1000-1500 (æ—¥æœ¬èª) | æ–‡è„ˆä¿æŒã¨ãƒãƒ©ãƒ³ã‚¹ |
| chunk_overlap | 150-300 (15-20%) | é‡è¤‡ã¨ç²¾åº¦ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ• |
| ã‚¨ãƒ©ãƒ¼å‡¦ç† | å¿…é ˆ | æœ¬ç•ªé‹ç”¨ã§ã®å®‰å®šæ€§ |
| ãƒ­ã‚®ãƒ³ã‚° | è©³ç´°ã« | ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚° |

**è¨­è¨ˆã®åŸºæœ¬æ–¹é‡**: 
ã€Œå‹•ãã€ã ã‘ã§ãªãã€Œå®‰å…¨ã«å¤‰æ›´ã§ãã‚‹æ§‹æˆã€ã‚’ç›®æŒ‡ã™ âœ…
